#!/usr/bin/env python3
"""
UI/UXæ±‚äººãƒ¬ãƒ¼ãƒ€ãƒ¼ CLI

ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ â†’ æ­£è¦åŒ– â†’ ã‚¹ã‚³ã‚¢ä»˜ä¸ ã‚’1ã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œ
"""

import argparse
import json
import os
import sys
from datetime import date
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    load_dotenv(PROJECT_ROOT / ".env")
except ImportError:
    pass

from src.models import RawJob, NormJob
from src.pipeline.score import calculate_score, extract_matched_skills
from src.pipeline.normalize import normalize, NormalizedResult

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹
DEFAULT_INPUT = PROJECT_ROOT / "data" / "out" / "jobs_raw.jsonl"
DEFAULT_OUTPUT = PROJECT_ROOT / "data" / "out" / "jobs_norm.jsonl"

# LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
LLM_AVAILABLE = False
try:
    from src.pipeline.llm_score import calculate_llm_score, LLMScoreResult
    import anthropic
    LLM_AVAILABLE = True
except ImportError:
    pass


def load_raw_jobs(input_path: Path) -> list[RawJob]:
    """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰RawJobãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    jobs = []

    with open(input_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue

            try:
                data = json.loads(line)
                # JSONã‹ã‚‰RawJobã¸ãƒãƒƒãƒ”ãƒ³ã‚°
                posted_date = None
                if data.get("posted_or_updated_at"):
                    try:
                        posted_date = date.fromisoformat(data["posted_or_updated_at"])
                    except ValueError:
                        pass

                raw_job = RawJob(
                    source=data.get("source", "unknown"),
                    company_name=data.get("company_name", ""),
                    job_title=data.get("job_title", ""),
                    url=data.get("url", ""),
                    posted_date=posted_date,
                    description=data.get("description", ""),
                    location=data.get("location", ""),
                    employment_type=data.get("employment_type", ""),
                    raw_html="",
                )
                jobs.append(raw_job)

            except json.JSONDecodeError as e:
                print(f"âš ï¸  è¡Œ{line_num}: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ - {e}", file=sys.stderr)

    return jobs


def process_jobs(raw_jobs: list[RawJob], use_llm: bool = False, llm_limit: int | None = None) -> list[dict]:
    """RawJobãƒªã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦ã‚¹ã‚³ã‚¢ä»˜ãæ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    results = []
    
    # LLMä½¿ç”¨æ™‚ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’äº‹å‰ã«ä½œæˆ
    llm_client = None
    if use_llm and LLM_AVAILABLE:
        try:
            llm_client = anthropic.Anthropic()
        except Exception as e:
            print(f"âš ï¸  LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            use_llm = False

    for i, raw in enumerate(raw_jobs):
        # 1. ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
        rule_score = calculate_score(raw)

        # 2. æ­£è¦åŒ–
        norm_result = normalize(raw, rule_score)

        # 3. LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        llm_result = None
        if use_llm and llm_client and (llm_limit is None or i < llm_limit):
            try:
                print(f"  ğŸ¤– LLMåˆ†æä¸­: {raw.company_name[:20]}...", end=" ", flush=True)
                llm_result = calculate_llm_score(raw, llm_client)
                print(f"âœ“ {llm_result.total_score}ç‚¹")
            except Exception as e:
                print(f"âœ— {e}")

        # 4. å‡ºåŠ›ç”¨dictã«å¤‰æ›
        output = {
            "source": norm_result.norm_job.source,
            "company_name": norm_result.norm_job.company_name,
            "job_title": norm_result.norm_job.job_title,
            "url": norm_result.norm_job.url,
            "posted_date": norm_result.norm_job.posted_date.isoformat() if norm_result.norm_job.posted_date else None,
            "description": norm_result.norm_job.description,
            "location": norm_result.norm_job.location,
            "employment_type": norm_result.norm_job.employment_type,
            "score": norm_result.norm_job.score,
            "skills": norm_result.norm_job.skills,
            "category": norm_result.category,
            "remote_type": norm_result.remote_type,
            "comp_min": norm_result.comp_min,
            "comp_max": norm_result.comp_max,
        }
        
        # LLMçµæœã‚’è¿½åŠ 
        if llm_result:
            output["llm_score"] = llm_result.total_score
            output["llm_dispatch_score"] = llm_result.dispatch_score
            output["llm_urgency_score"] = llm_result.urgency_score
            output["llm_skill_match_score"] = llm_result.skill_match_score
            output["llm_reason"] = llm_result.reason
            output["llm_tags"] = llm_result.tags
            # ç·åˆã‚¹ã‚³ã‚¢ã‚’LLMã‚¹ã‚³ã‚¢ã§ä¸Šæ›¸ãï¼ˆã¾ãŸã¯åŠ é‡å¹³å‡ï¼‰
            output["score"] = llm_result.total_score
        
        results.append(output)

    return results


def save_results(results: list[dict], output_path: Path) -> None:
    """çµæœã‚’JSONLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + "\n")


def print_summary(results: list[dict]) -> None:
    """å‡¦ç†çµæœã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    total = len(results)
    if total == 0:
        print("âš ï¸  å‡¦ç†å¯¾è±¡ã®æ±‚äººãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # ã‚¹ã‚³ã‚¢çµ±è¨ˆ
    scores = [r["score"] for r in results]
    avg_score = sum(scores) / total
    max_score = max(scores)
    min_score = min(scores)

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
    category_counts = {}
    for r in results:
        cat = r["category"]
        category_counts[cat] = category_counts.get(cat, 0) + 1

    # Top5è¡¨ç¤º
    top5 = sorted(results, key=lambda x: x["score"], reverse=True)[:5]

    print("\n" + "=" * 50)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 50)
    print(f"ç·ä»¶æ•°: {total}ä»¶")
    print(f"ã‚¹ã‚³ã‚¢: å¹³å‡ {avg_score:.1f} / æœ€é«˜ {max_score} / æœ€ä½ {min_score}")
    print()
    print("ğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
    for cat, count in sorted(category_counts.items(), key=lambda x: -x[1]):
        print(f"   {cat}: {count}ä»¶ ({count/total*100:.0f}%)")

    print()
    print("ğŸ† Top 5:")
    for i, job in enumerate(top5, 1):
        print(f"   {i}. [{job['score']}ç‚¹] {job['company_name']} - {job['job_title']}")

    print("=" * 50)


def main():
    parser = argparse.ArgumentParser(
        description="UI/UXæ±‚äººãƒ¬ãƒ¼ãƒ€ãƒ¼: ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ â†’ æ­£è¦åŒ– â†’ ã‚¹ã‚³ã‚¢ä»˜ä¸"
    )
    parser.add_argument(
        "-i", "--input",
        type=Path,
        default=DEFAULT_INPUT,
        help=f"å…¥åŠ›JSONLãƒ•ã‚¡ã‚¤ãƒ« (default: {DEFAULT_INPUT})"
    )
    parser.add_argument(
        "-o", "--output",
        type=Path,
        default=DEFAULT_OUTPUT,
        help=f"å‡ºåŠ›JSONLãƒ•ã‚¡ã‚¤ãƒ« (default: {DEFAULT_OUTPUT})"
    )
    parser.add_argument(
        "--top",
        type=int,
        default=None,
        help="ä¸Šä½Nä»¶ã®ã¿å‡ºåŠ›ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ä»¶ï¼‰"
    )
    parser.add_argument(
        "-q", "--quiet",
        action="store_true",
        help="ã‚µãƒãƒªãƒ¼è¡¨ç¤ºã‚’æŠ‘åˆ¶"
    )
    parser.add_argument(
        "--llm",
        action="store_true",
        help="LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ï¼ˆANTHROPIC_API_KEYç’°å¢ƒå¤‰æ•°ãŒå¿…è¦ï¼‰"
    )
    parser.add_argument(
        "--llm-limit",
        type=int,
        default=20,
        help="LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®æœ€å¤§ä»¶æ•°ï¼ˆAPIç¯€ç´„ç”¨ã€default: 20ï¼‰"
    )

    args = parser.parse_args()

    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if not args.input.exists():
        print(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input}", file=sys.stderr)
        print("   å…ˆã« scripts/generate_dummy.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„", file=sys.stderr)
        sys.exit(1)

    # LLMä½¿ç”¨ç¢ºèª
    use_llm = args.llm
    if use_llm:
        if not LLM_AVAILABLE:
            print("âš ï¸  LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ anthropic ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ã§ã™")
            print("   pip install anthropic")
            use_llm = False
        elif not os.getenv("ANTHROPIC_API_KEY"):
            print("âš ï¸  ANTHROPIC_API_KEY ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            use_llm = False
        else:
            print(f"ğŸ¤– LLMã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æœ‰åŠ¹ï¼ˆä¸Šé™: {args.llm_limit}ä»¶ï¼‰")

    # å‡¦ç†å®Ÿè¡Œ
    print(f"ğŸ“¥ èª­ã¿è¾¼ã¿ä¸­: {args.input}")
    raw_jobs = load_raw_jobs(args.input)
    print(f"   {len(raw_jobs)}ä»¶ã®æ±‚äººã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    print("âš™ï¸  ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ»æ­£è¦åŒ–ä¸­...")
    results = process_jobs(raw_jobs, use_llm=use_llm, llm_limit=args.llm_limit)

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    results.sort(key=lambda x: x["score"], reverse=True)

    # ä¸Šä½Nä»¶ã«çµã‚‹
    if args.top:
        results = results[:args.top]
        print(f"   ä¸Šä½{args.top}ä»¶ã«çµã‚Šè¾¼ã¿ã¾ã—ãŸ")

    # ä¿å­˜
    save_results(results, args.output)
    print(f"ğŸ“¤ ä¿å­˜å®Œäº†: {args.output}")

    # ã‚µãƒãƒªãƒ¼
    if not args.quiet:
        print_summary(results)


if __name__ == "__main__":
    main()

